<!DOCTYPE html>
<html lang="en">

  <head>
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link type="text/css" rel="stylesheet" href="/css/materialize.css" media="screen">
    <link type="text/css" rel="stylesheet" href="/css/sidenav-compact.css" media="screen">

    <!-- Let browser know website is optimized for mobile-->
    <meta name="viewport" content="width=device-width,initial-scale=1.0">

    <link rel="icon" href="/pics/favicon.ico" type="image/x-icon">
    <meta charset="UTF-8">
    <title>FAI - Fully Automatic Installation</title>
  </head>

  <body>
    <header>
      <!--#include virtual="/header.html" -->
    </header>
    <main>
      <div class="container">
        <div class="row">
          <div class="col s12">

<h3>FAI cluster installations</h3>

<ul class="col s12 browser-default">

<li>Thomas installed a 36 node cluster with 720 cores.
Each node has two E5-2690v2, 3.00GHz and 128GB of RAM. The parallel
installation of all nodes using FAI took 7 minutes. (2014)

<li>A new <a href="https://www.debian.org/News/2011/20110729">Beowulf cluster</a> at EDF (200 Tflops) which is 43rd in the latest TOP500 (June 2011), was partially installed using FAI.

<li> A huge cluster called <a href="https://wiki.debian.org/Teams/Publicity/DebianTimesTeam/PressReleases/GravitationalWaveDebianCluster">ATLAS</a>
 containing 1342 nodes at the Max Planck Institute for Gravitational Physics (2008). <a href="https://fai-project.org/reports/index.html#atlas">questionaire entry</a>,<a href="http://www.top500.org/system/9234">top500.org entry</a>
<a href="http://www.linux-magazin.de/NEWS/Atlas-Supercomputing-mit-Debian">German article</a>,<a href="http://www.heise.de/newsticker/meldung/Einstein-Cluster-Neuer-Supercomputer-fuer-die-Gravitationswellenforschung-209397.html">another article</a>


<li> <a href=http://globopt.dsi.unifi.it/gol/cluster.html>Experience gained in building a Linux cluster for GOL</a> by Lorenzo Campo and Daniele Manetti (2006)

<li> A very detailed <a href="http://www.physics.ubc.ca/mbelab/berserk_doc/steam-admin/html/">guide</a> (in <a href="
http://www.physics.ubc.ca/mbelab/berserk_doc/steam-admin/pdf/steam-admin.pdf">pdf</a>)
how a specific cluster was set up using FAI. (FAI 2.4, 2005)

<li>
<a href=http://www.hpc2n.umu.se/resources/sarek.html>HPC2N Opteron Cluster Sarek</a> is a
192 node dual AMD Opteron cluster, listed at rank 168 in the
top500.org list in june 2004.
<li>
A 25 node dual-CPU AMD Opteron 1.4GHz called <a
href=http://sites.google.com/site/rumbalab/resources/ravana>RAVANA</a>.
<li>
The IA64 cluster called <a href=http://www.pdc.kth.se/resources/computers/lucidor>Lucidor</a> was listed on place 354 in the Top500. (2003)
<li>
The <a href=http://www.hpc2n.umu.se/resources/super-cluster.html>HPC2N Super Cluster Seth</a>
with 120 dual Athlon nodes. This cluster was on the 94th position in the <a
href=http://www.top500.org/list/2002/06/>top500.org</a> supercomputer list in june 2002
<li>
The <a href=http://www.ai.sri.com/centibots/tech_design/index.html>100
Robots Project</a> (2002)
<li>
The university of California Santa Barbara has a
16 node dual AMD 1.8Ghz <a href=http://www.cs.ucsb.edu/~dbl/dblcluster.html>Beowulf cluster</a> for database and distributed systems research
<li>

23 nodes with Athlon XP are used by the TIK Experimental <a href="http://www.tik.ee.ethz.ch/~ddosvax/cluster/">Cluster Scylla</a>. (2004)
<li>
A 21 nodes with dual XEON 2.4GHz Beowulf cluster called  <A href="http://www.uni-saarland.de/fak7/rieger/shiva/">shiva</A> build with FAI 2.4beta.
A detailed <A href=https://lists.uni-koeln.de/pipermail/linux-fai/2003-February/001282.html>report</A>

<li>
A 21 nodes AMD 1GHz Beowulf cluster called  <A href="http://www.uni-saarland.de/fak7/rieger/hydra/">hydra</a>
<li>
A 28 nodes AMD 1GHz  <A href="https://web.archive.org/web/20100529113707/http://www.uni-koeln.de:80/rrzk/kompass/100/k10011a.html">Beowulf
cluster</a> build with FAI 2.5beta used for molecular thermodynamics and
simulation. <a href="../doc/RRZK-04.pdf">German article page 20ff</a>.
<li>
A <a href=http://g7-mac3.fy.chalmers.se/cgi-bin/twiki/view/Forte/WebHome>cluster</a>
at the department of Physical Resource Theory at the Chalmers University of Technology in Gothenburg/ Sweden. 10 Nodes with
a total of 13 CPUs.
<li>
A Beowulf cluster called <a
href=http://www.vision.ime.usp.br/~cage/Beowulf/>Biowulf/IME</a> with
16 nodes of 1.2 GHz AMD Athlon used for bioinformatic applications.
<li>
Several <a href=http://cluster-team.is.titech.ac.jp/modules/incontent/index.php?op=aff&option=0&url=ClusterIntro.html>clusters</a>
 at Matsulab of the Tokyo Institute of Technology are
installed using <a href=http://lucie.sf.net>lucie</a>, which is a mixture of FAI
and some other tools like ganglia, nagios, dolly+ and others. Most FAI
tasks are rewritten in ruby
but have the same functionality. They installed following clusters with
lucie: Presto I, Presto II, Presto III, OBI Grid Cluster

<li>
<A href="https://www.sintef.no/globalassets/project/evitameeting/2001/building_notes.pdf">Notes</A> and
<a href=https://www.sintef.no/globalassets/project/evitameeting/2001/building_foils.pdf>
foils</a> of building a Beowulf cluster from a winter school in 2001.
</ul>

<ADDRESS>
Tue, 29 Oct 2019 13:38:54 +0100
</ADDRESS>

</div>
</div>
</div>

    </main>

    <footer class="page-footer grey darken-3">
      <!--#include virtual="/footer.html" -->
    </footer>
    <!--JavaScript at end of body for optimized loading-->
    <script src="/js/materialize.js"></script>
    <script>
      M.AutoInit();
    </script>
  </body>
</html>
